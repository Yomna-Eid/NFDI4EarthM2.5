# Overview of data cube technologies and review of other emerging technologies

This document describes the state of the art solutions for local and cloud-based data storage and analysis for large gridded data.
In this document, we are going to describe the software that is currently used for the analysis of geospatial raster data. 
This is going to be a living document that is updated at least once a year, and other emerging technologies are going to be added in the future.
Geospatial raster data is used in very different user scenarios which can be used as points of view of the comparison of the different raster analysis tools.
There is the distinction between the used computing resources.
The computing resources can go from a single laptop, to a local cluster where the processing needs to be multi-threaded or distributed,
up to cloud computing environments which are composed of multiple clusters.
On their own laptop, scientists are able to control their computing environment but they would have to install the software themselves.
The software for laptops is mainly doing computations single-threaded, and there is a higher level of interactivity.
In High Performance Computing (HPC) environments, the software runs mainly multi-threaded or multi-core and the software is installed by a local system administrator. 
The computation environment is suited for larger processing and is not as interactive as on a local computer, because computation resources need to be mitigated by a job scheduler. 
In a cloud computing environment, like the Google Earth Engine (GEE) or the European Open Science Cloud (EOSC), users are bound to what the cloud provider allows on the platform and this can be quite closed - like the GEE, where only a special version of Python or Javascript is usable - or open as on the EOSC, where the user can use containers to run any software on the provided computing resources.

The tools that are described here can be used for different tasks. 
It can go from extraction of data for a given spatial and temporal extent, to the visualisation of the data, to the processing of the data in batches - which also includes machine learning training. These different tasks all have different software needs.
Another angle to look at is the size of the dataset. 
The size of the data set can be described spatially, going from a local dataset like a single satellite acquisition to a regional dataset to a global harmonised dataset. 
The size can also be in terms of the occupied data storage, from a few megabytes to multiple petabytes.
A classification of the type of the tool and the cloud readiness, describing, how well one can work on larger scale computations with this tool, is shown in Figure 1. 
![Classification of the tools into cloud readiness](overview.svg)

## Data formats and databases

In this section we discuss data formats and data bases that are often used for the handling of large gridded geospatial data. 

### Cloud Optimized Geotiffs
Cloud optimized Geotiffs (COG) are geotiff files which are organized, so that they can be hosted on an HTTP file server. 
This allows more efficient workflows on the cloud. 
COGs, in contrast to plain geotiffs, can be opened only partially - so there is no need to download the whole file, but you can access the parts of the file that are actually needed. 
The cloud optimized geotiff files can be used like normal tiff files, and 
therefore this format is supported by many libraries and software solutions. 


### HDF5

### NetCDF

NetCDF stands for Network Common Data Form and is one of the standard data formats in the geosciences. It is a binary format. The development for NetCDF started in 1988 by UCAR. A NetCDF file is self describing, which means, that it includes a header that describes the data that is included in the netcdf file. 
The most common used NetCDF version is NetCDF-4 which is based on the [HDF 5](#hdf5) format. 
It allows for efficient subsetting but it can not be accessed multi-threaded.


### TileDB 
TileDB is an open source universal storage engine for dense and sparse multidimensional arrays. In May 2017, TileDB spun out of Intel Labs and the MIT. TileDB allows parallel I/O and supports both local as well as remote storage systems (i.e. object stores, HDFS and Lustre). Data is stored in tiles/chunks. TileDB provides filters like compression and byte shuffling that can be applied on the chunk/tile level. Instead of writing the data in place, TileDB creates a new fragment with each write operations. While this idea of fragments improves latency for write operations, this introduces overhead for read operations.

### Zarr

Zarr is a data format for handling of large N-dimensional typed arrays. It focuses on support for distributed storage systems (i.e. object stores). 
It aims to provide efficient I/O for parallel computing.
It can handle different chunks and there are mutliple extensions of the data format for different use cases. It can handle compression. 
It is for data sets that are larger than RAM. The computations on these datasets should be parallizable.



## Open Source Software solutions

### EarthDataLab.jl

### Rasters.jl

### Rasdaman (DLR ?)

Rasdaman is an open source Array/Datacube Database System, which pioneered the whole field. They offer an SQL-like query language called rasql for data definition, retrieval and manipulation. Rasql embeds into standard SQL, sets and implements the ISO 9075 SQL Part 15 for Multi-Dimensional Arrays. It is set up as a client server system.  
Datasets have to be imported to the server with rasql. There are different client implementations from Rasdaman: a command-line utility, a python and web client. All of them offer access to the server through rasql. Other third-party clients for different languages and use cases are available as well.

### OpenEO

[OpenEO](https://openeo.org) is an application programming interface (API) developed by its namesake Horizon2020 project, providing a 'neutral' connection between clients and back-ends. 
The three official client libraries currently available are in R, Python, and JavaScript (for web developers). 
It allows users to by-pass the issue of using language-specific and data-provider-specific (cloud back-end) APIs, instead using a unified and simple API schema to connect to back-end data providers and their services. 
This allows easy comparison between back-ends, in terms of capability and cost, as well as combining the multiple sources in a joint analysis.

It is also available as a downloadable [QGIS-plugin](https://openeo.org/documentation/1.0/qgis/), so that users can explore the available openEO back-ends, as well as make further analyses and visualisation steps in the QGIS enviromnent.

### XArray
Xarray is a Python package, that provides an array type with labels and dimension names on top of a NumPy array. Dimensions, coordinates and attributes gives a more intuitive, more concise and less error-prone developer experience.  Xarray allows to apply operations along dimension names, select values of the array based on the label and not only on the integer positions. The mathematical operations are broadcasted across multiple dimensions not based on the array shape, but based on the array labels. 
You can keep track of metadata as a python dictionary. 
You do not need to keep track of the order of the arrays and you do not need to align dimensions with added dimensions of length one.

### XCube


### Iris

Iris is a python package for the analysis and visualisation of Earth science data. Its data model is based on the [[CF Conventions]]. The visualisation is based on [[matplotlib]] and [[cartopy]]. 
The data formats that can be used with Iris are:
[[NetCDF]], [[GRIB]] and [[PP]]. It also has a plugin system available to include other formats.
The Iris package builds upon [[numpy]] and [[dask]].  
It interoperates with the wider python ecosystem by using the standard numpy dask array types as underlying data storage. 

### Open Data Cube

The Open Data Cube (ODC) is a Python-based geospatial data management and analysis software.
The ODC can be used to catalogue large amounts of data and to provide them as a Python API for analysis. 
It is mainly used for the analysis of earth observation data in the framework of regional or national data cube platforms.

### stars (Uni Münster?)

### terra


## Cloud solutions

### Google Earth Engine

### DIAS

### EOSC

### OpenEO

To provide broader accessibility to the openEO project for users lacking the necessary infrastructure, the openEO API was further developed into its stand-alone platform for interactive usage as the web-based editor [OpenEO Hub](https://hub.openeo.org). Users can create a 30-day trial account to explore or process available data collections using code-scripts or in a user-friendly graphical process workflow with pre-defined, as well as user-defined, functions.

## Miscellaneous Technologies

### Spatio Temporal Asset Catalog (STAC) (Uni Münster ?)

### Interplanetary File System

### DataLad
